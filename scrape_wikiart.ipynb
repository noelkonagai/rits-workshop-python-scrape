{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RITS Workshop: Data Scraping with Python\n",
    "\n",
    "In this Jupyter notebook, you will see the code with explanation that will enable you to scrape panting images as wel as the data associated with these paintings.\n",
    "\n",
    "\n",
    "- Instructor: Noel Konagai\n",
    "- Email: noel.konagai@nyu.edu\n",
    "\n",
    "Feel free to contact me for individual follow-up consultations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests, json, math, urllib.request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the page length\n",
    "\n",
    "Our page has a \"load more\" button. Everytime this button is clicked, a new request is sent by our browser to the server, which returns a JSON file. The number of pages can be scraped by sending a request with the first page, and retrieving the 'PageSize' in the response JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.wikiart.org/en/paintings-by-style/cubism?json=2&page='\n",
    "\n",
    "def page_length():\n",
    "    r = requests.get('https://www.wikiart.org/en/paintings-by-style/cubism?json=2&page=1')\n",
    "    json_data = json.loads(r.text)\n",
    "    page_size = json_data['PageSize']\n",
    "    num_paintings = json_data['AllPaintingsCount']\n",
    "    num_pages = math.ceil(num_paintings/page_size)\n",
    "    \n",
    "    return num_pages, num_paintings, page_size\n",
    "\n",
    "num_pages, num_paintings, _ = page_length()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all the necessary data\n",
    "\n",
    "Write a function that will get the image URL, name of the artist, title, and the year from the given JSON file:\n",
    "\n",
    "- First, create empty lists for each of these, outside of your function. As we have lots of JSON files to open, we will keep appending new elements to each of these lists.\n",
    "- the general format to navigate to sub-branches of JSON files is by quoting in paranthesis the key\n",
    "- example: my_json_data['first_key']\n",
    "- you can find the appropriate keys if you view the JSON file in your browser\n",
    "- append each of the data to the apporpriate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls = []\n",
    "artist_names = []\n",
    "titles = []\n",
    "years = []\n",
    "\n",
    "def get_info(response_json, page_size):\n",
    "\n",
    "    for i in range(page_size):\n",
    "\n",
    "        painting = response_json['Paintings'][i]\n",
    "        image_urls.append(painting['image'])\n",
    "        artist_names.append(painting['artistName'])\n",
    "        titles.append(painting['title'])\n",
    "        years.append(painting['year'])\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all the JSON responses\n",
    "\n",
    "Write a function that will page from 1 to page_size and get the respective JSON responses:\n",
    "- write a for function that goes from 0 to num_pages\n",
    "- your request url should be in the format of base_url plus the number of the page\n",
    "- send the request with requests.get(your_url)\n",
    "- create a JSON data with json.loads(your_request.text)\n",
    "- find the number of paintings in the JSON file\n",
    "- run the function get_info(your_json_data, num_of_paintings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def open_all_json():\n",
    "\n",
    "    for i in range(num_pages):\n",
    "        clear_output()\n",
    "        print(str(i + 1) + \"/\" + str(num_pages) + \" pages have been opened\")\n",
    "        request_url = base_url + str(i + 1)\n",
    "        r = requests.get(request_url)\n",
    "        json_data = json.loads(r.text)\n",
    "        page_size = len(json_data['Paintings'])\n",
    "        get_info(json_data, page_size)\n",
    "        \n",
    "        if i == (num_pages - 1):\n",
    "            print('Done')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 pages have been opened\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "open_all_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking whether the number of URLs collected matches the number of paintings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of URLs match the number of paintings\n"
     ]
    }
   ],
   "source": [
    "def sanity_check():\n",
    "\n",
    "    if len(image_urls) == num_paintings:\n",
    "        print('The number of URLs match the number of paintings')\n",
    "    else:\n",
    "        print('Something went wrong')\n",
    "        \n",
    "sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading all the image files\n",
    "\n",
    "Write a function that downloads all the image files:\n",
    "- loop through the image_urls list\n",
    "- use urllib.request.urlretrieve(image_url, \"path + filename.jpg\")\n",
    "- hint: you can have a variable i = 0, to which you add 1 after every url: you could use this i in str(i).jpg to name your file\n",
    "- during the workshop, we won't have time to wait for all the files to be downloaded, so we will interrupt the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make sure that non-ascii characters are removed from the url, we pass the url through urllib.parse.quote(your_url)\n",
    "\n",
    "import urllib.parse as up\n",
    "\n",
    "def download_images(image_urls, start_imgID, end_imgID):\n",
    "    \n",
    "    num = end_imgID - start_imgID\n",
    "    \n",
    "    for i in range(num):\n",
    "        url = image_urls[start_imgID]\n",
    "        first_part = url[:36]\n",
    "        second_part = up.quote(url[36:])\n",
    "        quoted_url = first_part + second_part\n",
    "        urllib.request.urlretrieve(quoted_url, './cubism/' + str(start_imgID) + \".jpg\")\n",
    "        start_imgID += 1\n",
    "        \n",
    "    print('Done')\n",
    "    \n",
    "    return\n",
    "\n",
    "download_images(image_urls, 1070, 2908)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Pandas dataframe with information on the paintings\n",
    "\n",
    "Pandas is a library typically used for data analytics, but for our puroses it is a really handy tool with which we can easily create dataframes (think of them as spreadsheets). Below is the code to create a CSV file out of all the information that we collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(artist_names, titles, years, image_urls):\n",
    "    \n",
    "    # first we create series, think of them as columns in the spreadsheet\n",
    "    \n",
    "    s1 = pd.Series(artist_names)\n",
    "    s2 = pd.Series(titles)\n",
    "    s3 = pd.Series(years)\n",
    "    s4 = pd.Series(image_urls)\n",
    "    \n",
    "    d = {'artist': s1, 'title': s2, 'year': s3, 'url': s4}\n",
    "    \n",
    "    df = pd.DataFrame(data=d)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = create_dataframe(artist_names, titles, years, image_urls)\n",
    "\n",
    "# save it into a csv file\n",
    "df.to_csv('cubism.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
